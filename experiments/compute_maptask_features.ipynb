{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize.stanford import StanfordTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from utils import data_reader\n",
    "from utils import processing\n",
    "from utils import opf_helper\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Total of 18450 samples\n",
      "INFO:root:acknowledge - 3946\n",
      "INFO:root:instruct - 2934\n",
      "INFO:root:reply_y - 2225\n",
      "INFO:root:check - 1503\n",
      "INFO:root:explain - 1475\n",
      "INFO:root:align - 1283\n",
      "INFO:root:ready - 1281\n",
      "INFO:root:query_yn - 1173\n",
      "INFO:root:clarify - 840\n",
      "INFO:root:reply_n - 646\n",
      "INFO:root:reply_w - 607\n",
      "INFO:root:query_w - 537\n",
      "INFO:root:Total of 4426 samples\n",
      "INFO:root:acknowledge - 913\n",
      "INFO:root:instruct - 686\n",
      "INFO:root:reply_y - 490\n",
      "INFO:root:ready - 426\n",
      "INFO:root:explain - 414\n",
      "INFO:root:check - 375\n",
      "INFO:root:query_yn - 264\n",
      "INFO:root:align - 241\n",
      "INFO:root:clarify - 228\n",
      "INFO:root:reply_w - 163\n",
      "INFO:root:reply_n - 117\n",
      "INFO:root:query_w - 109\n",
      "INFO:root:Total of 3282 samples\n",
      "INFO:root:acknowledge - 625\n",
      "INFO:root:instruct - 566\n",
      "INFO:root:reply_y - 440\n",
      "INFO:root:ready - 291\n",
      "INFO:root:query_yn - 283\n",
      "INFO:root:align - 235\n",
      "INFO:root:explain - 210\n",
      "INFO:root:check - 199\n",
      "INFO:root:reply_w - 121\n",
      "INFO:root:clarify - 111\n",
      "INFO:root:query_w - 101\n",
      "INFO:root:reply_n - 100\n",
      "INFO:gensim.utils:loading EuclideanKeyedVectors object from ../vsms/wglove.840B.300d.bin\n",
      "INFO:gensim.utils:loading syn0 from ../vsms/wglove.840B.300d.bin.syn0.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute syn0norm to None\n",
      "INFO:gensim.utils:loaded ../vsms/wglove.840B.300d.bin\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# /\\ hidding Stanford Parser warning messages\n",
    "\n",
    "TOK_PATH    = '../tokenizer/stanford-corenlp-3.9.0.jar'\n",
    "MODEL_PATH  = '../vsms/wglove.840B.300d.bin'\n",
    "\n",
    "DATASET_T = '../datasets/clean/maptask_train.tsv'\n",
    "DATASET_D = '../datasets/clean/maptask_dev.tsv'\n",
    "DATASET_E = '../datasets/clean/maptask_test.tsv'\n",
    "\n",
    "FEATURES_FILE = './maptask_opf/maptask_samples.txt'\n",
    "MIN_WORD_FREQ = 2\n",
    "\n",
    "X_train, y_train = data_reader.read_dataset(DATASET_T)\n",
    "X_dev,   y_dev   = data_reader.read_dataset(DATASET_D)\n",
    "X_test,  y_test  = data_reader.read_dataset(DATASET_E)\n",
    "\n",
    "model     = KeyedVectors.load(MODEL_PATH)\n",
    "tokenizer = StanfordTokenizer(TOK_PATH)\n",
    "\n",
    "X_tok_t, word_freq = processing.tokenize_stanford(X_train, tokenizer)\n",
    "X_tok_d, _         = processing.tokenize_stanford(X_dev, tokenizer)\n",
    "X_tok_e, _         = processing.tokenize_stanford(X_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Vocab size:   1790\n",
      "INFO:root:Keeping:      1052 (58.77%)\n",
      "INFO:gensim.models.keyedvectors:precomputing L2-norms of word weight vectors\n",
      "WARNING:root:1119 sentences without representation.\n",
      "WARNING:root:743 OOV words\n",
      "WARNING:root:340 sentences without representation.\n",
      "WARNING:root:382 OOV words\n",
      "WARNING:root:194 sentences without representation.\n",
      "WARNING:root:252 OOV words\n"
     ]
    }
   ],
   "source": [
    "pruned_vocab = processing.keep_common_words(word_freq, MIN_WORD_FREQ)\n",
    "\n",
    "X_emb_t = processing.tok_sentence_to_vec(X_tok_t, pruned_vocab, model, normalize_sentence=4,\n",
    "                                         normalize_word=False, show_logs=1)\n",
    "X_emb_d = processing.tok_sentence_to_vec(X_tok_d, pruned_vocab, model, normalize_sentence=4,\n",
    "                                         normalize_word=False, show_logs=1)\n",
    "X_emb_e = processing.tok_sentence_to_vec(X_tok_e, pruned_vocab, model, normalize_sentence=4,\n",
    "                                         normalize_word=False, show_logs=1)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_emb_t = encoder.fit_transform(y_train)\n",
    "y_emb_d = encoder.transform(y_dev)\n",
    "y_emb_e = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([X_emb_t, X_emb_d, X_emb_e])\n",
    "y = np.vstack([y_emb_t[:, None], y_emb_d[:, None], y_emb_e[:, None]]).flatten()\n",
    "\n",
    "# writing all features file, so distances can be computed\n",
    "opf_helper.write_opf_format(\n",
    "    X,\n",
    "    y + 1, # OPF indices start at 1\n",
    "    FEATURES_FILE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
