{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Cleans and formats the dialog transcriptions for the Map Task dataset, as the text\n",
    "    is mostly aligned. Dialog interruptions are marked as double dashes, ie: 'lake fa--',\n",
    "    letters between quotes indicate shape, ie: \"u\"-shaped turn or 'zee' shape.\n",
    "    \n",
    "    The text already comes lowercased, so the only option is replacing the shape figures\n",
    "    by a token, if desired.\n",
    "    \n",
    "    [CONTENTS]\n",
    "        - Preprocessing\n",
    "        - Splitting into train/dev/test\n",
    "        - Data peeking\n",
    "        - Label occurrence statistics\n",
    "        - Checking <uncodable> class\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from os import path, getcwd\n",
    "from collections import defaultdict\n",
    "\n",
    "DATASET_FILE = './maptask/all_transcripts.txt'\n",
    "TRAIN_PATH   = './clean/maptask_train.tsv'\n",
    "DEV_PATH     = './clean/maptask_dev.tsv'\n",
    "TEST_PATH    = './clean/maptask_test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_conversation():\n",
    "    return {\n",
    "        'name': None,\n",
    "        'utterances': list(),\n",
    "        'turns': 0\n",
    "    }\n",
    "\n",
    "def get_conv_name(conv_header):\n",
    "    text = conv_header[0]\n",
    "    return re.findall(':\\s(.+?)\\;', text)[0]\n",
    "\n",
    "class Preprocessor:\n",
    "    \"\"\"Simply replaces shape-figures if replace_shapes is true, otherwise does nothing.\"\"\"\n",
    "    \n",
    "    def preprocess(self, text):        \n",
    "        return re.sub(\"--|\\\"\", '', text).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 127 dialogs with 26567 utterances.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(DATASET_FILE, 'r')\n",
    "uncodable_samples = list()\n",
    "reader = csv.reader(file, delimiter='\\t')\n",
    "\n",
    "conversations = list()\n",
    "conv = make_conversation()\n",
    "\n",
    "pre = Preprocessor()\n",
    "\n",
    "# Reads the pooled file, splitting it into conversation dics for later\n",
    "# further splitting into train/test/dev\n",
    "first = next(reader)\n",
    "name = get_conv_name(first)\n",
    "\n",
    "conv['name'] = name\n",
    "counter = 1\n",
    "\n",
    "for line in reader:\n",
    "    # reached the header of the next conversation\n",
    "    if len(line) == 1:\n",
    "        conv['turns'] = len(conv['utterances'])\n",
    "        \n",
    "        conversations.append(conv)\n",
    "        conv = make_conversation()\n",
    "\n",
    "        name = get_conv_name(line)\n",
    "        conv['name'] = name\n",
    "\n",
    "        counter = 1\n",
    "\n",
    "    else:\n",
    "        speaker, label, text = line\n",
    "        \n",
    "        text = pre.preprocess(text)\n",
    "        idd = '{}_{}'.format(name, counter)\n",
    "        \n",
    "        if label == 'uncodable':\n",
    "            uncodable_samples.append((idd, speaker, label, text))\n",
    "            continue\n",
    "        \n",
    "        conv['utterances'].append((idd, speaker, label, text))\n",
    "        counter += 1\n",
    "\n",
    "# Brief summary\n",
    "n_turns = sum([conv['turns'] for conv in conversations])\n",
    "n_conversations = len(conversations)\n",
    "print('Parsed {} dialogs with {} utterances.\\n'.format(n_conversations, n_turns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split summary:\n",
      " - Train: 89   70.08%\n",
      " - Dev:   19   14.96%\n",
      " - Test:  18   14.17%\n",
      "\n",
      "\n",
      " - Train: [q1ec1, q1ec2, q1ec3, q1ec4, q1ec5, q1ec6, q1ec7, q1ec8, q1nc1, q1nc2, q1nc3, q1nc4, q1nc5, q1nc6, q1nc7, q1nc8, q2ec1, q2ec2, q2ec3, q2ec4, q2ec5, q2ec6, q2ec7, q2ec8, q2nc1, q2nc2, q2nc3, q2nc4, q2nc5, q2nc6, q2nc7, q2nc8, q3ec1, q3ec2, q3ec3, q3ec4, q3ec5, q3ec6, q3ec7, q3ec8, q3nc1, q3nc2, q3nc3, q3nc4, q3nc5, q3nc6, q3nc7, q3nc8, q4ec1, q4ec2, q4ec3, q4ec4, q4ec5, q4ec6, q4ec7, q4ec8, q4nc1, q4nc2, q4nc3, q4nc4, q4nc5, q4nc6, q4nc7, q4nc8, q5ec1, q5ec2, q5ec3, q5ec4, q5ec5, q5ec6, q5ec7, q5ec8, q5nc1, q5nc2, q5nc3, q5nc4, q5nc5, q5nc6, q5nc7, q5nc8, q6ec1, q6ec2, q6ec3, q6ec4, q6ec5, q6ec6, q6ec7, q6ec8, q6nc1].\n",
      "\n",
      " - Dev: [q6nc3, q6nc4, q6nc5, q6nc6, q6nc7, q6nc8, q7ec1, q7ec2, q7ec3, q7ec4, q7ec5, q7ec6, q7ec7, q7ec8, q7nc1, q7nc2, q7nc3, q7nc4, q7nc5].\n",
      "\n",
      " - Test: [q7nc6, q7nc7, q7nc8, q8ec1, q8ec2, q8ec3, q8ec4, q8ec5, q8ec6, q8ec7, q8ec8, q8nc1, q8nc2, q8nc3, q8nc4, q8nc5, q8nc6, q8nc7].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train/dev/test\n",
    "\n",
    "train_set = conversations[0:89]\n",
    "dev_set = conversations[90:109]\n",
    "test_set = conversations[109:]\n",
    "\n",
    "print('Split summary:')\n",
    "print(' - Train: {}   {:.4}%'.format(len(train_set), len(train_set) / n_conversations * 100))\n",
    "print(' - Dev:   {}   {:.4}%'.format(len(dev_set), len(dev_set) / n_conversations * 100))\n",
    "print(' - Test:  {}   {:.4}%'.format(len(test_set), len(test_set) / n_conversations * 100))\n",
    "\n",
    "print('\\n')\n",
    "print(' - Train: [{}].\\n'.format(', '.join([node['name'] for node in train_set])))\n",
    "print(' - Dev: [{}].\\n'.format(', '.join([node['name'] for node in dev_set])))\n",
    "print(' - Test: [{}].\\n'.format(', '.join([node['name'] for node in test_set])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# persisting data\n",
    "\n",
    "def persist_split(filename, conversations):\n",
    "    \"\"\"Stores a given split as a tsv file.\"\"\"\n",
    "    clean_file = open(filename, 'w')\n",
    "    clean_writer = csv.writer(clean_file, delimiter='\\t')\n",
    "    \n",
    "    clean_writer.writerow(['id', 'speaker', 'label', 'clean'])\n",
    "    for conv in conversations:\n",
    "        for utt in conv['utterances']:\n",
    "            clean_writer.writerow(utt)\n",
    "                         \n",
    "    clean_file.close()\n",
    "\n",
    "\n",
    "persist_split(TRAIN_PATH, train_set)\n",
    "persist_split(DEV_PATH, dev_set)\n",
    "persist_split(TEST_PATH, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-label-     \t-original text (90 chars)-                                                                \n",
      "reply_w     \twell                                                                                      \t\n",
      "ready       \tright                                                                                     \t\n",
      "instruct    \tnow go right                                                                              \t\n",
      "check       \tcross the rope bridge                                                                     \t\n",
      "explain     \tah this is the same one i got with lynn we spent ages on it                               \t\n",
      "reply_n     \toh                                                                                        \t\n",
      "reply_y     \tyeah got an apache camp                                                                   \t\n",
      "acknowledge \tuh-huh                                                                                    \t\n",
      "ready       \tokay                                                                                      \t\n",
      "check       \tstraight up                                                                               \t\n",
      "ready       \tnow                                                                                       \t\n",
      "reply_y     \tokay                                                                                      \t\n",
      "instruct    \tdirectly below the start                                                                  \t\n",
      "ready       \twell                                                                                      \t\n",
      "instruct    \tright now take that take the line                                                         \t\n",
      "align       \tokay                                                                                      \t\n",
      "instruct    \tgo for it                                                                                 \t\n",
      "align       \tand then so you get to the top of the pine tree                                           \t\n",
      "query_yn    \thave you got the parked van                                                               \t\n",
      "acknowledge \tright a camera shop                                                                       \t\n",
      "align       \tsee how there's about a centimetre                                                        \t\n",
      "clarify     \tnorth to the left of the of the old temple                                                \t\n",
      "acknowledge \tokay                                                                                      \t\n",
      "acknowledge \tsouth                                                                                     \t\n",
      "ready       \twell                                                                                      \t\n",
      "acknowledge \tokay                                                                                      \t\n",
      "reply_y     \tyeah                                                                                      \t\n",
      "instruct    \tand then                                                                                  \t\n",
      "instruct    \tunderneath draw a line to your right and straight along at a slight angle rising up toward\t\n",
      "query_yn    \tare springboks marked on the map                                                          \t\n"
     ]
    }
   ],
   "source": [
    "# Data peeking\n",
    "\n",
    "AMOUNT_PEEKS = 30\n",
    "\n",
    "conversation_no = random.sample(range(n_conversations), AMOUNT_PEEKS)\n",
    "utterance_no    = random.sample(range(50), AMOUNT_PEEKS)\n",
    "\n",
    "print('{:12.12}\\t{:90.90}'.format('-label-', '-original text (90 chars)-'))\n",
    "for cn, un in zip(conversation_no, utterance_no):\n",
    "    sample = conversations[cn]['utterances'][un]\n",
    "    print('{:12.12}\\t{:90.90}\\t'.format(sample[2], sample[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-label-\t     -frequency- \n",
      "acknowledge    5556\n",
      "instruct       4234\n",
      "reply_y        3199\n",
      "explain        2152\n",
      "check          2119\n",
      "ready          2051\n",
      "align          1774\n",
      "query_yn       1735\n",
      "clarify        1190\n",
      "reply_w        913\n",
      "reply_n        875\n",
      "query_w        769\n"
     ]
    }
   ],
   "source": [
    "# Label occurrence statistics\n",
    "\n",
    "ftable = defaultdict(int)\n",
    "for conversation in conversations:\n",
    "    for utt in conversation['utterances']:\n",
    "        ftable[utt[2]] += 1\n",
    "        \n",
    "ftable = sorted(ftable.items(), key=lambda x: x[1], reverse=True)\n",
    "print('-label-\\t     -frequency- ')\n",
    "for label, freq in ftable:\n",
    "    print('{:14.12} {}'.format(label, freq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (keras_env)",
   "language": "python",
   "name": "keras_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
